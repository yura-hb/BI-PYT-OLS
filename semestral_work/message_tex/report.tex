%%
%% Created in 2018 by Martin Slapak
%% last update:		2020-02-09
%%
%% Based on file for NRP report LaTeX class by Vit Zyka (2008)
%% enhanced for MI-MVI (2018) and tuned for BI-PYT (2020)
%%
%% Compilation:
%% >pdflatex report
%% >bibtex report
%% >pdflatex report
%% >pdflatex report

\documentclass[czech]{pyt-report}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{OLS}

\author{Yury Hayeu}
\affiliation{ČVUT--FIT}
\email{hayeuyur@fit.cvut.cz}

\def\file#1{{\tt#1}}

\begin{document}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Úvod}
Úkolem semestrální práce byla implementace modulu, který implementoval metodu nejmenších čtverců s použitím python balíčků \textbf{Numpy} a \textbf{Pandas}.
Po implementaci by měla být provedena explorační analýza dat a predikce výstupních hodnot pro dataset obsahující informaci o bydlení v Bostonu \cite{housing}.

Lineární regrese je metoda, účelem které je hledaní nejlepší aproximace koeficientů polynomu:
\begin{equation}
y = \alpha_0 + \alpha_1 * x_1 + ... + \alpha_n * x_n
\end{equation}
Koeficient$\alpha_0$ se nazývá bias. Koeficienty $\alpha_1 , ... , \alpha_n$ jsou váhy. Vstupní data je matice velikosti $(m, n)$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Výpočet biasu}
Implementace modulu redukuje výpočet biasu pomocí následující úvahy:
\begin{multline*}
y = \alpha_0 + \alpha_1 * x_1 + ... + \alpha_n * x_n =\\
  \alpha_0 * 1 + \alpha_1 * x_1 + ... + \alpha_n * x_n = \\
  \alpha_0 * x_0 + \alpha_1 * x_1 + ... + \alpha_n * x_n
\end{multline*}
Modul přidává vstupní matici zleva sloupec jedniček na začátku aproximace a predikce hodnot.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metody}
Modul implementuje následující metody:

\begin{enumerate}
\item Statistická lineární regrese je základní metoda, která spočítá váhy podle vzorce\cite{lin_reg}:
\begin{equation}
\alpha = (X^T X)^{-1} X^T Y
\end{equation}
$X$ je vstupní data. \\
$Y$ je cíl aproximace. \\
$\alpha$ je vektor vah. \\
$X^T$ je transponovaná matice. \\
$(X^T X)^{-1}$ je inverzní matice. \\
\item Gradient descent(GD) je metoda, která  iterativně spočítá váhy. Základní jednotkou GD je cost funkce, která spočítá chybu aproximace. Cílem semestrální práce bylo použití metody nejmenších čtverců, proto cost funkce je následující:
\begin{equation}
\epsilon = mean((X^{'} - Y)^2)
\end{equation}

$X^{'}$ je predikovaná hodnota. \\
$n$ - je počet řádků matic X a Y.\\

Potřebujeme zavést následující definice:

\begin{enumerate}
\item \textbf{Počet iteraci} je počet, kolikrát bude aproximovat funkce.
\item \textbf{Tolerance} je prahová hodnota, která ukazuje změnu v cost funkci. Pokud během dvě iterace se změna chyby bude menší než tolerance, pak se aproximace funkce zastaví.
\item \textbf{Learning step} (budeme značit $\beta$) je hodnota, která určuje rychlost aproximace.
\end{enumerate}

Gradient funkce určuje směr (kladný nebo záporný) a změnu koeficientů aproximace funkce. Jedná se o derivaci výstupní funkce:

\begin{equation}
gradient = - 2/n *  X^T * (X^{'} - Y)
\end{equation}

$gradient$ je vektor koeficientů \\
$X^{'}$ je predikovaná hodnota. \\
$Y$ je cíl aproximace. \\
$n$ je počet záznamů. \\

Aproximace funkce je následující :

\begin{equation}
noveKoeficienty += learningStep * gradient
\end{equation}

\textit{Algoritmus Gradient Descent}:

\begin{enumerate}
\item Spočítej predikovanou hodnotu pro vstupní matici X.
\item Spočítej gradient podle vzorce (4).
\item Spočítej váhy podle vzorce (5).
\item Spočítej chybu aproximaci, pokud změna v chybě aproximace je menší než tolerance, ukonči aproximaci.
\end{enumerate}

\item Stochastic gradient descent je modifikace GD pro větší rozsah dat. Modul implementuje základní verzí SGD, která aproximuje hodnoty funkce podle jednoho záznamů. \cite{sgd_ref}
\item Minibatch gradient descent je modifikace SGD, která aproximuje hodnoty funkce podle balíčku záznamů
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --- VYSLEDKY
\section{Výsledky}
Výsledkem semestrální práce je balíček OLS a jupyter notebook \textbf{EDA.ipynb}, kde se provádí předzpracovaní dat a vizualizace lineární regresi pro sloupce s vysokou korelaci.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --- ZAVER
\section{Závěr}
Balíček OLS je vhodný pro hledaní vah pří malém počtu záznamů, pří větším počtu záznamů by operace maticového násobení mohly používat zdroje GPU anebo nějaké jiné externí zdroje. Následujícím vylepšením by byla implementace různých druhů cost funkce a SGD metod.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --- Bibliography
%\bibliographystyle{plain-cz-online}
\bibliography{reference}

\end{document}
