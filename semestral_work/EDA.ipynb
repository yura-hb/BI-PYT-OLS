{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OLS.OLS import * \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data for EDA\n",
    "\n",
    "Import Boston dataset with the next attributes columns:\n",
    "\n",
    "1. *CRIM*      per capita crime rate by town\n",
    "2. *ZN*        proportion of residential land zoned for lots over  25,000 sq.ft.\n",
    "3. *INDUS*     proportion of non-retail business acres per town\n",
    "4. *CHAS*      Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. *NOX*       nitric oxides concentration (parts per 10 million)\n",
    "6. *RM*        average number of rooms per dwelling\n",
    "7. *AGE*       proportion of owner-occupied units built prior to 1940\n",
    "8. *DIS*       weighted distances to five Boston employment centres\n",
    "9. *RAD*       index of accessibility to radial highways\n",
    "10. *TAX*      full-value property-tax rate per \\$10000\n",
    "11. *PTRATIO*  pupil-teacher ratio by town\n",
    "12. *BRATIO*        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. *LSTAT*    % lower status of the population\n",
    "14. *MEDV*     Median value of owner-occupied homes in \\$1000's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'housing.data'\n",
    "dataset_columns = ['CR', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'BRATIO', 'LSTAT', 'MEDV']\n",
    "\n",
    "dataset = pd.read_csv('datasets/housing.data', \n",
    "                      delim_whitespace=True, \n",
    "                      header=None, \n",
    "                      names=dataset_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset analysis\n",
    "\n",
    "Perform simple dataset analysis on correlation, atd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorCorrelatedFeatures(value):\n",
    "    \"\"\"\n",
    "    Color higly correlated pairs of features\n",
    "    \"\"\"\n",
    "    color = 'green' if abs(value) > 0.74 and abs(value) != 1 else 'white'\n",
    "    return 'background-color: %s' % color\n",
    "    \n",
    "\n",
    "dataset.corr().style.applymap(colorCorrelatedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's investigate mostly correlated features\n",
    "\n",
    "I will plot them as scatter plots to see the next points:\n",
    "\n",
    "1. Mostly correlated parts of the graph\n",
    "2. Possible outliers of the 4 plots\n",
    "3. The necessity of scaling some axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(axes, x_feature, y_feature, x_label, y_label, color, description):\n",
    "    \"\"\"\n",
    "    Plots scatter plot with the specified parameters\n",
    "    \"\"\"\n",
    "    axes.scatter(x_feature, y_feature, c=color)\n",
    "    axes.set_title(description)\n",
    "    axes.set_xlabel(x_label)\n",
    "    axes.set_ylabel(y_label)\n",
    "\n",
    "def plotFeatures():\n",
    "    \n",
    "    figure, (axes1, axes2) = plt.subplots(2, 2, figsize = (12, 12))\n",
    "\n",
    "    description = \"Nitric oxides concentration \\nto proportion of non-retail business acres per town\"\n",
    "    plot(axes1[0], dataset['NOX'], dataset['INDUS'], 'NOX', 'INDUS', 'g', description)\n",
    "\n",
    "    description = \"Weighted distances to five Boston employment centres\\n to nitric oxides concentration\"\n",
    "    plot(axes2[0], dataset['DIS'], dataset['NOX'], 'DIS', 'NOX', 'y', description)\n",
    "\n",
    "    description = \"Full-value property-tax rate per $10000 \\nto index of accessibility to radial highways\"\n",
    "    plot(axes1[1], dataset['TAX'], dataset['RAD'], 'TAX', 'RAD', 'b', description)\n",
    "    \n",
    "    description = \"Weighted distances to five Boston employment centrer \\nto  proportion of owner-occupied units built prior to 1940\"\n",
    "    plot(axes2[1], dataset['DIS'], dataset['AGE'], 'DIS', 'AGE', 'r', description)\n",
    "    \n",
    "    figure.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plotFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Basic min-max normalization\n",
    "    \"\"\"\n",
    "    return(series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "def filter_max(series: pd.Series, maximum_value):\n",
    "    \"\"\"\n",
    "    Replaces outliers with the mean value\n",
    "    \"\"\"\n",
    "    mean = series.mean()\n",
    "    return series.apply(lambda x: x if x < maximum_value else mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the mostly data is not clean and need some preparation:\n",
    "\n",
    "### Plot NOX to INDUS:\n",
    "As I see NOX is the percentage in range from 0 to 1, but mostly features as in range from 0 to 0.7, so remove outliers and normalise INDUS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['NOX'] = filter_max(dataset['NOX'], 0.7)\n",
    "dataset['INDUS'] = filter_max(dataset['INDUS'], 15)\n",
    "dataset['INDUS'] = normalize(dataset['INDUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NOX to the DIS\n",
    "Here we can try to normalize dis feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['DIS'] = normalize(dataset['DIS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot RAD to TAX\n",
    "Perform only basic min-max normalization, as removing outliers has shown a decrease in the high correlation between two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['TAX'] = normalize(dataset['TAX'])\n",
    "dataset['RAD'] = normalize(dataset['RAD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot AGE to DIS\n",
    "1. Age is the proportion from 0 to 100, so normalize to range 0 to 1\n",
    "2. Dis also can be normalised to the range 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['DIS'] = filter_max(dataset['DIS'], 0.8)\n",
    "dataset['AGE'] = normalize(dataset['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr().style.applymap(colorCorrelatedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS\n",
    "\n",
    "Let's try to perform basic linear regression on the current features. \n",
    "OLS module supports different configurations and different regressions:\n",
    "\n",
    "1. Basic linear regression, which is stastically calculated, using matrix operations\n",
    "2. Gradient descent and its specifications, like (SGD and minibatch GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.sample(frac = 0.8)\n",
    "test_data = dataset.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression predictions\n",
    "\n",
    "Perform basic statistical linear regression:\n",
    "\n",
    "This type of the regression provides the minimal MSE error and provides best fit for the data, however, the computation complexity is near O(n^2) to O(n^3) depending on the implementation of the matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_model(train_data, labels, target) -> OLS:\n",
    "    \"\"\"\n",
    "    Create linear regression model and perform fit\n",
    "    \n",
    "    Input:\n",
    "        labels - the list of the labels from the dataset\n",
    "        targets - the name of the target from the dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    model = OLS()\n",
    "    model.fit(\n",
    "        np.array(train_data[labels]), \n",
    "        np.array(train_data[[target]])\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def render_plot(axes, dataset: pd.DataFrame, prediction, \n",
    "                label: str, target: str, split: str):\n",
    "    \"\"\"\n",
    "        Renders plot on the matplotlib.axes\n",
    "        \n",
    "        Input:\n",
    "            axes - axes to draw on\n",
    "            dataset - train and test datasets\n",
    "            prediction - vector of predictions\n",
    "            label - feature label\n",
    "            target - target label\n",
    "            split - string, which shows, which split is it\n",
    "    \"\"\"\n",
    "    \n",
    "    color = (np.random.rand(), np.random.rand(), np.random.rand())\n",
    "    \n",
    "    axes.scatter(dataset[[label]], dataset[[target]], c=[color])\n",
    "    \n",
    "    axes.set_title(\"Regression result between {} and {} ({})\".format(label, target, split))\n",
    "    axes.set_xlabel(label)\n",
    "    axes.set_ylabel(target)\n",
    "    \n",
    "    axes.plot(\n",
    "        dataset[[label]], \n",
    "        prediction,\n",
    "        c = 'r'\n",
    "    )\n",
    "\n",
    "def visualize_linear_reg_result(model: OLS, train_data, test_data, label, target):\n",
    "    \"\"\"\n",
    "    Draw a scatter plot with the prediction line:\n",
    "    \n",
    "    Input:\n",
    "        label - the name of the label from the dataset\n",
    "        target - the name of the target from the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    slopes = model.slopes\n",
    "    \n",
    "    prediction = model.predict(np.array(train_data[[label]]))\n",
    "    print(\"Train data score: \", model.score(np.array(train_data[[target]]), prediction))\n",
    "    \n",
    "    figure, (axes1, axes2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "    \n",
    "    render_plot(axes1, train_data, prediction, label, target, 'train_data')\n",
    "\n",
    "    prediction = model.predict(np.array(test_data[[label]]))\n",
    "    print(\"Test data score: \", model.score(np.array(test_data[[target]]), prediction))\n",
    "    \n",
    "    render_plot(axes2, test_data, prediction, label, target, 'test_data')\n",
    "    \n",
    "    figure.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linear_model = create_linear_model(train_data, ['NOX'], 'INDUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(linear_model, train_data, test_data, 'NOX', 'INDUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linear_model = create_linear_model(train_data, ['DIS'], 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(linear_model, train_data, test_data, 'DIS', 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linear_model = create_linear_model(train_data, ['RAD'], 'TAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(linear_model, train_data, test_data, 'RAD', 'TAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linear_model = create_linear_model(train_data, ['DIS'], 'AGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(linear_model, train_data, test_data, 'DIS', 'AGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent\n",
    "\n",
    "Gradient descent is the approach, which is used to minimize some function by repeated iterated move in the direction of the minimum.\n",
    "\n",
    "There are 3 basic parameters for GD:\n",
    "\n",
    "1. Number of the iterations is the first one and it shows, how much iterations should be performed\n",
    "2. Tolerance is the threshold of the difference in the cost function values. As we use GD, the cost function is the MSE.\n",
    "3. Learning step tells the model, how fast should it move to the minimum of the function. The better the learning learning step is chosen, the faster the model will find the minimum. In comparison, a big learning step can result into overflow and a small learning step can significantly decrease the speed of the approximation.\n",
    "\n",
    "Current implementation supports all these options and sets `slopes_records` and `cost_records` to visualize the process\n",
    "\n",
    "Also OLS module supports:\n",
    "\n",
    "1. Stochastic Gradient Descent is the gd, but takes only one sample from the training dataset per iteration. (It is the simplest implementation, where the learning step plays the key-role, other implementations can be found [here](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "2. Minibatch Gradient Descent is the sgd, but takes m samples from the trainit dataset per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gd_model(train_data, \n",
    "                    labels, \n",
    "                    target, \n",
    "                    number_of_iterations = 1000,\n",
    "                    tolerance = 0.00001, \n",
    "                    learning_step = 0.001,\n",
    "                    batch_size = 1,\n",
    "                    type = 'GD') -> OLS:\n",
    "    \"\"\"\n",
    "    Create gd model and perform fit\n",
    "    \n",
    "    Input:\n",
    "        labels - the list of the labels from the dataset\n",
    "        targets - the name of the target from the dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    model = OLS(number_of_iterations, tolerance, learning_step, batch_size, type)\n",
    "    model.fit(\n",
    "        np.array(train_data[labels]), \n",
    "        np.array(train_data[[target]])\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_approximation_process(model: OLS, train_data, label, target, skipOffset = 20):\n",
    "    \"\"\"\n",
    "    Renders the process approximation using the cost records from the model\n",
    "    \n",
    "    Input:\n",
    "        model - OLS model\n",
    "        train_data - dataset for train\n",
    "        label - label from the train dataset\n",
    "        target - target label from the train dataset\n",
    "        skipOffset - shows the number of records to skip\n",
    "    \"\"\"\n",
    "    mse_errors = model.cost_records\n",
    "    slopes_records = [model.slopes_records[0]]\n",
    "    slopes_records += model.slopes_records[::skipOffset]\n",
    "    slopes_records += [model.slopes_records[-1]]\n",
    "    \n",
    "    number_of_iterations = len(mse_errors)\n",
    "    \n",
    "    figure, (axes1, axes2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "    \n",
    "    axes1.set_title(\"MSE error\")\n",
    "    axes1.plot(np.arange(number_of_iterations), mse_errors)\n",
    "    \n",
    "    minimum = train_data[[label]].min()\n",
    "    maximum = train_data[[label]].max()\n",
    "    \n",
    "    lin_space = np.linspace(minimum, maximum, 100)\n",
    "    \n",
    "    axes2.set_title(\"Learning process\")\n",
    "    axes2.scatter(train_data[[label]], train_data[target], c='r')\n",
    "    \n",
    "    for slope in enumerate(slopes_records):\n",
    "        color = 'r' if slope[0] < len(slopes_records) - 1 else 'b'\n",
    "        linewidth = 0.5 if slope[0] < len(slopes_records) - 1 else 1\n",
    "        slopes = np.flip(slope[1].reshape(len(slope[1])), 0)\n",
    "        function = np.poly1d(slopes)\n",
    "        \n",
    "        axes2.plot(lin_space, function(lin_space), linewidth = linewidth, c=color)\n",
    "\n",
    "    figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video animation\n",
    "\n",
    "Visualize the learning process at the speed of the 30 FPS and saves the output video to the file `videos/label_target_model_type_animation.mp4`. Add manually to the notebook, as execution can take time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_approximation_process(model: OLS, train_data, label, target, skipOffset = 1):\n",
    "    \"\"\"\n",
    "    Renders the process approximation using the cost records from the model and\n",
    "    saves the result to the basic_animation.mp4\n",
    "    \n",
    "    Input:\n",
    "        model - OLS model\n",
    "        train_data - dataset for train\n",
    "        label - label from the train dataset\n",
    "        target - target label from the train dataset\n",
    "        skipOffset - shows the number of records to skip\n",
    "    \"\"\"\n",
    "    mse_errors = model.cost_records\n",
    "    slopes_records = [model.slopes_records[0]]\n",
    "    slopes_records += model.slopes_records[::skipOffset]\n",
    "    slopes_records += [model.slopes_records[-1]]\n",
    "    \n",
    "    number_of_iterations = len(slopes_records)\n",
    "    \n",
    "    figure, (axes1, axes2) = plt.subplots(1, 2, figsize = (12, 6))\n",
    "    \n",
    "    axes1.set_title(\"MSE error\")\n",
    "    axes1.set_xlabel(\"Number of iterations\")\n",
    "    axes1.set_ylabel(\"MSE error\")\n",
    "    \n",
    "    mse_plot = axes1.plot()\n",
    "    \n",
    "    minimum = train_data[[label]].min()\n",
    "    maximum = train_data[[label]].max()\n",
    "    \n",
    "    lin_space = np.linspace(minimum, maximum, 100)\n",
    "    \n",
    "    axes2.set_title(\"Learning process\")\n",
    "    axes2.scatter(train_data[[label]], train_data[target], c='r')\n",
    "    axes2.set_xlabel(label)\n",
    "    axes2.set_ylabel(target)\n",
    "    axes2.set_ylim(bottom=train_data[target].min() - 0.1)\n",
    "    \n",
    "    line_plot, = axes2.plot(lin_space, lin_space)\n",
    "    \n",
    "    def animate(frame):\n",
    "        # Render mse error\n",
    "        if frame < len(mse_errors):\n",
    "            axes1.plot(np.arange(number_of_iterations)[:frame], mse_errors[:frame], c='r')\n",
    "\n",
    "        # Render slopes\n",
    "        slope = slopes_records[frame]\n",
    "        slopes = np.flip(slope.reshape(len(slope)), 0)\n",
    "        function = np.poly1d(slopes)\n",
    "        \n",
    "        color = 'r' if frame < len(slopes_records) - 1 else 'y'\n",
    "        linewidth = 0.5 if frame < len(slopes_records) - 1 else 1\n",
    "        \n",
    "        predictions = function(lin_space)\n",
    "\n",
    "        line_plot.set_ydata(predictions)\n",
    "        line_plot.set_color(color)\n",
    "        line_plot.set_linewidth(linewidth)\n",
    "        line_plot.set_alpha(0.8)\n",
    "    \n",
    "    animation = FuncAnimation(figure, animate, frames = number_of_iterations)\n",
    "    animation.save('videos/{}-{}-{}.mp4'.format(label, target, model.type), fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOX/INDUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(train_data, ['NOX'], 'INDUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'NOX', 'INDUS')\n",
    "render_approximation_process(gd_model, train_data, 'NOX', 'INDUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data, \n",
    "    ['NOX'], \n",
    "    'INDUS', \n",
    "    number_of_iterations=3000,\n",
    "    learning_step=0.01, \n",
    "    type='SGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'NOX', 'INDUS')\n",
    "render_approximation_process(gd_model, train_data, 'NOX', 'INDUS', skipOffset = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data, \n",
    "    ['NOX'], \n",
    "    'INDUS', \n",
    "    batch_size=20,\n",
    "    learning_step = 0.01,\n",
    "    type='MGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'NOX', 'INDUS')\n",
    "render_approximation_process(gd_model, train_data, 'NOX', 'INDUS', skipOffset = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIS/NOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(train_data, ['DIS'], 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'DIS', 'NOX')\n",
    "render_approximation_process(gd_model, train_data, 'DIS', 'NOX', skipOffset = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data, \n",
    "    ['DIS'], \n",
    "    'NOX',\n",
    "    number_of_iterations=1000,\n",
    "    tolerance = 0,\n",
    "    learning_step=0.1, \n",
    "    type='SGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'DIS', 'NOX')\n",
    "render_approximation_process(gd_model, train_data, 'DIS', 'NOX', skipOffset = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data,\n",
    "    ['DIS'], \n",
    "    'NOX', \n",
    "    tolerance=0,\n",
    "    batch_size=40, \n",
    "    learning_step=0.01,\n",
    "    type='MGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'DIS', 'NOX')\n",
    "render_approximation_process(gd_model, train_data, 'DIS', 'NOX', skipOffset = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAD/TAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(train_data, ['RAD'], 'TAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'RAD', 'TAX')\n",
    "render_approximation_process(gd_model, train_data, 'RAD', 'TAX', skipOffset = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data, \n",
    "    ['RAD'],\n",
    "    'TAX',\n",
    "    number_of_iterations=1000,\n",
    "    learning_step=0.1,\n",
    "    type='SGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'RAD', 'TAX')\n",
    "render_approximation_process(gd_model, train_data, 'RAD', 'TAX', skipOffset = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data,\n",
    "    ['RAD'], \n",
    "    'TAX', \n",
    "    batch_size=40, \n",
    "    learning_step=0.01,\n",
    "    type='MGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'RAD', 'TAX')\n",
    "render_approximation_process(gd_model, train_data, 'RAD', 'TAX', skipOffset = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIS/AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(train_data, ['DIS'], 'AGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'DIS', 'AGE')\n",
    "render_approximation_process(gd_model, train_data, 'DIS', 'AGE', skipOffset = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data, \n",
    "    ['DIS'],\n",
    "    'AGE',\n",
    "    learning_step=0.1,\n",
    "    type='SGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'DIS', 'AGE')\n",
    "render_approximation_process(gd_model, train_data, 'DIS', 'AGE', skipOffset = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data,\n",
    "    ['DIS'], \n",
    "    'AGE', \n",
    "    batch_size=40, \n",
    "    learning_step=0.01,\n",
    "    type='MGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_linear_reg_result(gd_model, train_data, test_data, 'DIS', 'AGE')\n",
    "render_approximation_process(gd_model, train_data, 'DIS', 'AGE', skipOffset = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "1. According to the results SGD and MGD, which are generally slower than the GD and simple linear regression. It is true, because the dataset is relatively small and on the bigger dataset with the bigger amount of the features, the result of SGD and MGD should win over GD and simple linear regression in time.\n",
    "2. GD is more stable than MGD from the view of finding the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At final, let's try to perform multiple-feature linear regression\n",
    "\n",
    "We will predict the concentration of nitric oxides basing on the person age and it's distance to Boston centers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "def print_score(model, train_data, test_data, labels, target):\n",
    "    prediction = model.predict(np.array(train_data[labels]))\n",
    "    print(\"Train data score: \", model.score(np.array(train_data[[target]]), prediction))\n",
    "    prediction = model.predict(np.array(test_data[labels]))\n",
    "    print(\"Test data score: \", model.score(np.array(test_data[[target]]), prediction))\n",
    "\n",
    "def render_3d(data, x_label, y_label, z_label):\n",
    "    figure = plt.figure(figsize=(6, 6))\n",
    "    axes = figure.add_subplot(111, projection='3d')\n",
    "    axes.set_xlabel(x_label)\n",
    "    axes.set_ylabel(y_label)\n",
    "    axes.set_zlabel(z_label)\n",
    "    axes.scatter(data[[x_label]], data[[y_label]], data[[z_label]], c='b', alpha=1, marker='^')\n",
    "\n",
    "    figure.tight_layout()\n",
    "    \n",
    "    figure.show()\n",
    "    \n",
    "    return figure, axes\n",
    "    \n",
    "def render_3d_lin_reg_result(model, data, x_label, y_label, z_label):\n",
    "    figure, axes = render_3d(data, x_label, y_label, z_label)\n",
    "    print(np.array(model.predict(data[[x_label, y_label]])).flat)\n",
    "    \n",
    "    x = np.arange(0.0, 1.0, 0.02)\n",
    "    y = np.arange(0.0, 1.0, 0.02)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    Z = model.slopes[0] + model.slopes[1] * X + model.slopes[2] * Y\n",
    "    \n",
    "    axes.plot_surface(X, Y, Z, alpha=0.3)\n",
    "    \n",
    "    figure.tight_layout()\n",
    "    \n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_3d(train_data, 'DIS', 'AGE', 'NOX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linear_model = create_linear_model(train_data, ['DIS', 'AGE'], 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(linear_model, train_data, test_data, ['DIS', 'AGE'], 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_3d_lin_reg_result(linear_model, train_data, 'DIS', 'AGE', 'NOX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data,\n",
    "    ['DIS', 'AGE'], \n",
    "    'NOX',\n",
    "    type='GD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(gd_model, train_data, test_data, ['DIS', 'AGE'], 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_3d_lin_reg_result(gd_model, train_data, 'DIS', 'AGE', 'NOX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data, \n",
    "    ['DIS', 'AGE'],\n",
    "    'NOX',\n",
    "    number_of_iterations=3000,\n",
    "    tolerance = 0.0000001,\n",
    "    learning_step=0.01,\n",
    "    type='SGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(gd_model, train_data, test_data, ['DIS', 'AGE'], 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_3d_lin_reg_result(gd_model, train_data, 'DIS', 'AGE', 'NOX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_model = create_gd_model(\n",
    "    train_data,\n",
    "    ['DIS', 'AGE'], \n",
    "    'NOX', \n",
    "    tolerance=0.000001,\n",
    "    batch_size=40,\n",
    "    learning_step=0.001,\n",
    "    type='MGD'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(gd_model, train_data, test_data, ['DIS', 'AGE'], 'NOX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_3d_lin_reg_result(gd_model, train_data, 'DIS', 'AGE', 'NOX')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
